{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><a name=\"yelp\"></a></p>\n",
    "### Scrape Yelp Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Find the pattern of url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.139 Safari/537.36'\n",
    "            }\n",
    "\n",
    "response = requests.get('https://www.yelp.com/biz/shake-shack-washington-3', headers=headers).text\n",
    "soup = BeautifulSoup(response, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "num_reviews = soup.find('span', attrs={'class': 'review-count rating-qualifier'}).string\n",
    "num_reviews = int(re.search('\\d+', num_reviews).group())\n",
    "print(num_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "url_list = []\n",
    "for i in range(0, num_reviews, 20):\n",
    "    url_list.append('https://www.yelp.com/biz/shake-shack-washington-3?start='+str(i))\n",
    "#print(url_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Find all the review divs on the page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "reviews = soup.find_all('div', attrs={'class':'review review--with-sidebar'})\n",
    "print(len(reviews))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Apply to all the pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished page 1\n",
      "Finished page 2\n",
      "Finished page 3\n",
      "Finished page 4\n",
      "Finished page 5\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import time\n",
    "import random\n",
    "\n",
    "def scrape_single_page(reviews, csvwriter):\n",
    "    for review in reviews:\n",
    "        dic = {}\n",
    "        try:\n",
    "            username = review.find('a', attrs={'class': 'user-display-name js-analytics-click'}).text\n",
    "        except:\n",
    "            username = \"\"\n",
    "        try:\n",
    "            location = review.find('li', attrs={'class': 'user-location responsive-hidden-small'}).text.strip()\n",
    "        except:\n",
    "            location = \"\"\n",
    "        try:\n",
    "            friends_n = review.find('li', attrs={'class': 'friend-count responsive-small-display-inline-block'}).get_text().strip()\n",
    "        except:\n",
    "            friends_n = \"\"\n",
    "        try:\n",
    "            reviews_n = review.find('li', attrs={'class': 'review-count responsive-small-display-inline-block'}).get_text().strip()\n",
    "        except:\n",
    "            reviews_n = \"\"\n",
    "        try:\n",
    "            photos_n = review.find('li', attrs={'class': 'photo-count responsive-small-display-inline-block'}).get_text().strip()\n",
    "        except:\n",
    "            photos_n = \"\"\n",
    "        try:\n",
    "            elite = review.find('li', attrs={'class': 'is-elite responsive-small-display-inline-block'}).get_text().strip()\n",
    "        except:\n",
    "            elite = \"\"\n",
    "        try:\n",
    "            date = review.find('span', attrs={'class': 'rating-qualifier'}).text.strip()\n",
    "        except:\n",
    "            date = \"\"\n",
    "        try:\n",
    "            rating = review.find('img', attrs={'class': 'offscreen'}).get('alt')\n",
    "            rating = float(re.search('\\d+', rating).group())\n",
    "        except:\n",
    "            rating = \"\"\n",
    "        try:\n",
    "            check_in = review.find('li', attrs={'class': 'review-tags_item'}).get_text().strip()\n",
    "        except:\n",
    "            check_in = \"\"\n",
    "        try:\n",
    "            content = review.find('p').text\n",
    "        except:\n",
    "            content = \"\"\n",
    "        try:\n",
    "            useful_n = review.find('a', attrs={'class': 'ybtn ybtn--small useful js-analytics-click'}).get_text().strip()[-1]\n",
    "        except:\n",
    "            useful_n = \"\"\n",
    "        try:\n",
    "            date_reply = review.find('span', attrs={'class': 'bullet-after'}).get_text().strip()\n",
    "        except:\n",
    "            date_reply = \"\"\n",
    "        dic['username'] = username\n",
    "        dic['location'] = location\n",
    "        dic['friends_n'] = friends_n\n",
    "        dic['reviews_n'] = reviews_n\n",
    "        dic['photos_n'] = photos_n\n",
    "        dic['elite'] = elite\n",
    "        dic['date'] = date\n",
    "        dic['rating'] = rating\n",
    "        dic['check_in'] = check_in\n",
    "        dic['content'] = content\n",
    "        dic['useful_n'] = useful_n\n",
    "        dic['date_reply'] = date_reply\n",
    "        csvwriter.writerow(dic.values())\n",
    "    \n",
    "with open('ss_navy_yard.csv', 'w') as csvfile:\n",
    "    review_writer = csv.writer(csvfile)\n",
    "    for index, url in enumerate(url_list):\n",
    "        response = requests.get(url, headers=headers).text\n",
    "        soup = BeautifulSoup(response, 'html.parser')\n",
    "        reviews = soup.find_all('div', attrs={'class':'review review--with-sidebar'})\n",
    "        scrape_single_page(reviews, review_writer)\n",
    "        # Random sleep to avoid getting banned from the server\n",
    "        time.sleep(random.randint(1,3))\n",
    "        # Log the progress\n",
    "        print('Finished page ' + str(index + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
